

# 9 jobs in the finite regime with 500 graphs at different levels

bsub -n 50 -W 72:00 python -m src.run_experiments --n_workers -1 --k 3 --G 300 --runs 8 --p_min 12 --p_max 12 --w_min 0.5 --w_max 1 --var_min 0 --var_max 1 --int_min 0 --int_max 1 --batch_size 20000 --max_iter 50 --alpha 0.0002 --finite --n 10 --random_state 0 --tag may9l
bsub -n 50 -W 72:00 python -m src.run_experiments --n_workers -1 --k 3 --G 300 --runs 8 --p_min 12 --p_max 12 --w_min 0.5 --w_max 1 --var_min 0 --var_max 1 --int_min 0 --int_max 1 --batch_size 20000 --max_iter 50 --alpha 0.0002 --finite --n 100 --random_state 0 --tag may9l
bsub -n 100 -W 120:00 python -m src.run_experiments --n_workers -1 --k 3 --G 300 --runs 8 --p_min 12 --p_max 12 --w_min 0.5 --w_max 1 --var_min 0 --var_max 1 --int_min 0 --int_max 1 --batch_size 20000 --max_iter 50 --alpha 0.0002 --finite --n 1000 --random_state 0 --tag may9l

bsub -n 50 -W 72:00 python -m src.run_experiments --n_workers -1 --k 3 --G 300 --runs 8 --p_min 12 --p_max 12 --w_min 0.5 --w_max 1 --var_min 0 --var_max 1 --int_min 0 --int_max 1 --batch_size 20000 --max_iter 50 --alpha 0.0001 --finite --n 10 --random_state 0 --tag may9m
bsub -n 50 -W 72:00 python -m src.run_experiments --n_workers -1 --k 3 --G 300 --runs 8 --p_min 12 --p_max 12 --w_min 0.5 --w_max 1 --var_min 0 --var_max 1 --int_min 0 --int_max 1 --batch_size 20000 --max_iter 50 --alpha 0.0001 --finite --n 100 --random_state 0 --tag may9m
bsub -n 100 -W 120:00 python -m src.run_experiments --n_workers -1 --k 3 --G 300 --runs 8 --p_min 12 --p_max 12 --w_min 0.5 --w_max 1 --var_min 0 --var_max 1 --int_min 0 --int_max 1 --batch_size 20000 --max_iter 50 --alpha 0.0001 --finite --n 1000 --random_state 0 --tag may9m

bsub -n 50 -W 72:00 python -m src.run_experiments --n_workers -1 --k 3 --G 300 --runs 8 --p_min 12 --p_max 12 --w_min 0.5 --w_max 1 --var_min 0 --var_max 1 --int_min 0 --int_max 1 --batch_size 20000 --max_iter 50 --alpha 0.002 --finite --n 10 --random_state 0 --tag may9h
bsub -n 50 -W 72:00 python -m src.run_experiments --n_workers -1 --k 3 --G 300 --runs 8 --p_min 12 --p_max 12 --w_min 0.5 --w_max 1 --var_min 0 --var_max 1 --int_min 0 --int_max 1 --batch_size 20000 --max_iter 50 --alpha 0.002 --finite --n 100 --random_state 0 --tag may9h
bsub -n 100 -W 120:00 python -m src.run_experiments --n_workers -1 --k 3 --G 300 --runs 8 --p_min 12 --p_max 12 --w_min 0.5 --w_max 1 --var_min 0 --var_max 1 --int_min 0 --int_max 1 --batch_size 20000 --max_iter 50 --alpha 0.002 --finite --n 1000 --random_state 0 --tag may9h

# 2 jobs for the population setting

bsub -n 50 -W 100:00 python -m src.run_experiments --n_workers 49 --k 3 --G 500 --runs 8 --p_min 15 --p_max 15 --w_min 0.5 --w_max 1 --var_min 0 --var_max 1 --int_min 0 --int_max 1 --batch_size 20000 --random_state 0 --tag may9pop
bsub -n 50 -W 100:00 python -m src.run_experiments --n_workers 49 --k 3 --G 500 --runs 8 --p_min 15 --p_max 15 --w_min 0.5 --w_max 1 --var_min 0 --var_max 1 --int_min 0 --int_max 1 --batch_size 20000 --random_state 1 --tag may9pop

# Generate ABCD dataset

python -m src.run_experiments --save_dataset data --n_workers 1 --k 3 --G 100 --runs 32 --p_min 12 --p_max 12 --w_min 0.5 --w_max 1 --var_min 0 --var_max 1 --int_min 0 --int_max 1 --batch_size 20000 --max_iter 100 --random_state 0

# 6 jobs on the ABCD dataset

bsub -n 50 -W 24:00 python -m src.run_experiments --load_dataset dataset_3 --n_workers 49 --runs 4 --batch_size 20000 --max_iter 50 --alpha 0.0002 --finite --n 10 --n_obs 50 --abcd --tag may9abcd
bsub -n 50 -W 24:00 python -m src.run_experiments --load_dataset dataset_3 --n_workers 49 --runs 4 --batch_size 20000 --max_iter 50 --alpha 0.0002 --finite --n 10 --n_obs 100 --abcd --tag may9abcd
bsub -n 50 -W 24:00 python -m src.run_experiments --load_dataset dataset_3 --n_workers 49 --runs 4 --batch_size 20000 --max_iter 50 --alpha 0.0002 --finite --n 10 --n_obs 1000 --abcd --tag may9abcd

bsub -n 50 -W 24:00 python -m src.run_experiments --load_dataset dataset_3 --n_workers 49 --runs 4 --batch_size 20000 --i_mean 0 --i_var 2 --max_iter 50 --alpha 0.0002 --finite --n 10 --n_obs 50 --abcd --tag may9abcd2
bsub -n 50 -W 24:00 python -m src.run_experiments --load_dataset dataset_3 --n_workers 49 --runs 4 --batch_size 20000 --i_mean 0 --i_var 2 --max_iter 50 --alpha 0.0002 --finite --n 10 --n_obs 100 --abcd --tag may9abcd2
bsub -n 50 -W 24:00 python -m src.run_experiments --load_dataset dataset_3 --n_workers 49 --runs 4 --batch_size 20000 --i_mean 0 --i_var 2 --max_iter 50 --alpha 0.0002 --finite --n 10 --n_obs 1000 --abcd --tag may9abcd2


# 12 ABCD jobs

cp -r dataset_3 dataset_3_0
cp -r dataset_3 dataset_3_1
cp -r dataset_3 dataset_3_2
cp -r dataset_3 dataset_3_3
cp -r dataset_3 dataset_3_4
cp -r dataset_3 dataset_3_5
cp -r dataset_3 dataset_3_6
cp -r dataset_3 dataset_3_7
cp -r dataset_3 dataset_3_8
cp -r dataset_3 dataset_3_9
cp -r dataset_3 dataset_3_10
cp -r dataset_3 dataset_3_11

bsub -n 48 -W 100:00 -R "rusage[mem=3000]" python3 run_experiments.py -n 500 -b 50 -k 1 --boot 100 -s 2 --folder dataset_3_0 --strategy entropy --starting-samples 50
bsub -n 48 -W 100:00 -R "rusage[mem=3000]" python3 run_experiments.py -n 500 -b 50 -k 1 --boot 100 -s 2 --folder dataset_3_1 --strategy entropy --starting-samples 50
bsub -n 48 -W 100:00 -R "rusage[mem=3000]" python3 run_experiments.py -n 500 -b 50 -k 1 --boot 100 -s 2 --folder dataset_3_2 --strategy entropy --starting-samples 50
bsub -n 48 -W 100:00 -R "rusage[mem=3000]" python3 run_experiments.py -n 500 -b 50 -k 1 --boot 100 -s 2 --folder dataset_3_3 --strategy entropy --starting-samples 50

bsub -n 48 -W 100:00 -R "rusage[mem=3000]" python3 run_experiments.py -n 500 -b 50 -k 1 --boot 100 -s 2 --folder dataset_3_4 --strategy entropy --starting-samples 100
bsub -n 48 -W 100:00 -R "rusage[mem=3000]" python3 run_experiments.py -n 500 -b 50 -k 1 --boot 100 -s 2 --folder dataset_3_5 --strategy entropy --starting-samples 100
bsub -n 48 -W 100:00 -R "rusage[mem=3000]" python3 run_experiments.py -n 500 -b 50 -k 1 --boot 100 -s 2 --folder dataset_3_6 --strategy entropy --starting-samples 100
bsub -n 48 -W 100:00 -R "rusage[mem=3000]" python3 run_experiments.py -n 500 -b 50 -k 1 --boot 100 -s 2 --folder dataset_3_7 --strategy entropy --starting-samples 100

bsub -n 48 -W 100:00 -R "rusage[mem=3000]" python3 run_experiments.py -n 500 -b 50 -k 1 --boot 100 -s 2 --folder dataset_3_8 --strategy entropy --starting-samples 1000
bsub -n 48 -W 100:00 -R "rusage[mem=3000]" python3 run_experiments.py -n 500 -b 50 -k 1 --boot 100 -s 2 --folder dataset_3_9 --strategy entropy --starting-samples 1000
bsub -n 48 -W 100:00 -R "rusage[mem=3000]" python3 run_experiments.py -n 500 -b 50 -k 1 --boot 100 -s 2 --folder dataset_3_10 --strategy entropy --starting-samples 1000
bsub -n 48 -W 100:00 -R "rusage[mem=3000]" python3 run_experiments.py -n 500 -b 50 -k 1 --boot 100 -s 2 --folder dataset_3_11 --strategy entropy --starting-samples 1000


