{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing properties of the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib import gridspec\n",
    "import scipy\n",
    "from src import utils\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tex formatting for plots\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'serif','sans-serif':['Computer Modern Roman']})\n",
    "rc('text', usetex=True)\n",
    "#plt.rcParams[\"font.family\"] = \"serif\"\n",
    "#plt.rcParams[\"font.serif\"] = [\"Computer Modern Roman\"]\n",
    "\n",
    "# Set legend size\n",
    "from matplotlib.font_manager import FontProperties\n",
    "fontP = FontProperties()\n",
    "fontP.set_size('medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiments(filename):\n",
    "    f = open(filename, \"rb\")\n",
    "    results = pickle.load(f)\n",
    "    return results[0], results[1::]\n",
    "\n",
    "def merge_runs(old, new, min_merge=False):\n",
    "    if len(old) == len(new) or (len(old) < len(new) and min_merge):\n",
    "        for i in range(len(old)):\n",
    "            old[i] += new[i].copy()\n",
    "    else:\n",
    "        raise Exception(\"Cannot merge\")\n",
    "    return old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(filenames):\n",
    "    print(\"Loading %s\" % filenames[0])\n",
    "    cases, results = load_experiments(filenames[0])\n",
    "    for filename in filenames[1::]:\n",
    "        print(\"Loading %s\" % filename)\n",
    "        new_cases, new_results = load_experiments(filename)\n",
    "        cases += new_cases\n",
    "        for k in range(len(results)):\n",
    "            results[k] = merge_runs(results[k], new_results[k])\n",
    "    print(\"\\nLoaded a total of %d graphs with %d runs each\" % (len(results[0][0]), len(results[0])))\n",
    "    return cases, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(A,B,p):\n",
    "    a = np.zeros(p)\n",
    "    b = np.zeros(p)\n",
    "    a[list(A)] = 1\n",
    "    b[list(B)] = 1\n",
    "    return scipy.spatial.distance.hamming(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trajectories(results, cases):\n",
    "    runs = len(results[0])\n",
    "    N = len(results[0][0])\n",
    "    P = len(results)\n",
    "\n",
    "    no_ints = np.zeros((len(results), runs, N))\n",
    "    all_trajectories_ham = {}\n",
    "    all_lens_accepted = {}\n",
    "    all_lens_selection = {}\n",
    "    all_type1_errors = {}\n",
    "    names = []\n",
    "    for k, policy_runs in enumerate(results):\n",
    "        name = policy_runs[0][0].policy\n",
    "        print(\"Processing results for %s policy\" % name, end=\"\")\n",
    "        names.append(name)\n",
    "        trajectories_ham = []\n",
    "        lens_accepted = []\n",
    "        lens_selection = []\n",
    "        type1_errors = []\n",
    "        for i,run_results in enumerate(policy_runs):\n",
    "            no_ints[k, i,:] = list(map(lambda result: len(result.interventions()), run_results))\n",
    "            for j, result in enumerate(run_results):\n",
    "                estimates = result.estimates() + [result.estimate]\n",
    "                trajectory_ham = list(map(lambda estimate: hamming_distance(cases[j].truth, estimate, cases[j].sem.p), estimates))\n",
    "                type1_error = list(map(lambda estimate: set.issubset(estimate, cases[j].truth), estimates))\n",
    "                trajectories_ham.append(trajectory_ham)\n",
    "                lens_accepted.append(result.no_accepted())\n",
    "                lens_selection.append(result.len_selection())\n",
    "                type1_errors.append(type1_error)\n",
    "        all_trajectories_ham[name] = trajectories_ham\n",
    "        all_lens_accepted[name] = lens_accepted\n",
    "        all_lens_selection[name] = lens_selection\n",
    "        all_type1_errors[name] = type1_errors\n",
    "        print(\" done\")\n",
    "    return all_trajectories_ham, all_type1_errors, all_lens_accepted, all_lens_selection, N, P, runs, names, no_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Experiments to load\n",
    "\n",
    "experiments = experiments = [\n",
    "[\"experiments/results_1587961452_k:3.0_G:500_runs:8_n_min:12_n_max:12_w_min:0.5_w_max:1.0_var_min:0.0_var_max:1.0_int_min:0.0_int_max:1.0_i_mean:10_i_var:1_random_state:0_finite:True_max_iter:50_n:10_alpha:0.0005_tag:apr25sl.pickle\"],\n",
    "[\"experiments/results_1587881500_k:3.0_G:500_runs:8_n_min:12_n_max:12_w_min:0.5_w_max:1.0_var_min:0.0_var_max:1.0_int_min:0.0_int_max:1.0_i_mean:10_i_var:1_random_state:0_finite:True_max_iter:50_n:100_alpha:0.0005_tag:apr25sl.pickle\"],\n",
    "[\"experiments/results_1587913432_k:3.0_G:500_runs:8_n_min:12_n_max:12_w_min:0.5_w_max:1.0_var_min:0.0_var_max:1.0_int_min:0.0_int_max:1.0_i_mean:10_i_var:1_random_state:0_finite:True_max_iter:50_n:1000_alpha:0.0005_tag:apr25sl.pickle\"],\n",
    "[\"experiments/results_1587936821_k:3.0_G:500_runs:8_n_min:12_n_max:12_w_min:0.5_w_max:1.0_var_min:0.0_var_max:1.0_int_min:0.0_int_max:1.0_i_mean:10_i_var:1_random_state:0_finite:True_max_iter:50_n:10_alpha:0.0025_tag:apr25sm.pickle\"],\n",
    "[\"experiments/results_1587872472_k:3.0_G:500_runs:8_n_min:12_n_max:12_w_min:0.5_w_max:1.0_var_min:0.0_var_max:1.0_int_min:0.0_int_max:1.0_i_mean:10_i_var:1_random_state:0_finite:True_max_iter:50_n:100_alpha:0.0025_tag:apr25sm.pickle\"],\n",
    "[\"experiments/results_1587908944_k:3.0_G:500_runs:8_n_min:12_n_max:12_w_min:0.5_w_max:1.0_var_min:0.0_var_max:1.0_int_min:0.0_int_max:1.0_i_mean:10_i_var:1_random_state:0_finite:True_max_iter:50_n:1000_alpha:0.0025_tag:apr25sm.pickle\"],\n",
    "[\"experiments/results_1587931361_k:3.0_G:500_runs:8_n_min:12_n_max:12_w_min:0.5_w_max:1.0_var_min:0.0_var_max:1.0_int_min:0.0_int_max:1.0_i_mean:10_i_var:1_random_state:0_finite:True_max_iter:50_n:10_alpha:0.005_tag:apr25sh.pickle\"],\n",
    "[\"experiments/results_1587874267_k:3.0_G:500_runs:8_n_min:12_n_max:12_w_min:0.5_w_max:1.0_var_min:0.0_var_max:1.0_int_min:0.0_int_max:1.0_i_mean:10_i_var:1_random_state:0_finite:True_max_iter:50_n:100_alpha:0.005_tag:apr25sh.pickle\"],\n",
    "[\"experiments/results_1588089424_k:3.0_G:500_runs:8_n_min:12_n_max:12_w_min:0.5_w_max:1.0_var_min:0.0_var_max:1.0_int_min:0.0_int_max:1.0_i_mean:10_i_var:1_random_state:0_finite:True_max_iter:50_n:1000_alpha:0.005_tag:apr25sh.pickle\"],\n",
    "]\n",
    "\n",
    "Trajectories = []\n",
    "LensAccepted = []\n",
    "LensSelection = []\n",
    "NoInts = []\n",
    "Type1Errors = []\n",
    "\n",
    "for i,filenames in enumerate(experiments):\n",
    "    print(\"\\n\\n %d/%d\" % (i, len(experiments)), end=\" \")\n",
    "    cases, results = load_results(filenames)\n",
    "    trajectories, type1errors, lens_accepted, lens_selection, N, P, runs, names, no_ints = generate_trajectories(results, cases)\n",
    "    if i==0:\n",
    "        prev_N, prev_P, prev_runs = N, P, runs\n",
    "    elif prev_N != N or prev_P != P or prev_runs != runs:\n",
    "        print(N, P, runs)\n",
    "        print(prev_N, prev_P, prev_runs)\n",
    "        raise Exception(\"Experiments have different number of graphs / policies / runs\")\n",
    "    Trajectories.append(trajectories)\n",
    "    LensAccepted.append(lens_accepted)\n",
    "    LensSelection.append(lens_selection)\n",
    "    NoInts.append(no_ints)\n",
    "    Type1Errors.append(type1errors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change in accepted sets vs. iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "plt.plot(LensAccepted[0][\"e\"][i], label=\"sp False, e\")\n",
    "plt.plot(LensAccepted[0][\"e + r\"][i], label=\"sp False, e + r\")\n",
    "plt.plot(LensAccepted[6][\"e\"][i], label=\"sp True, e\")\n",
    "plt.plot(LensAccepted[6][\"e + r\"][i], label=\"sp True, e + r\")\n",
    "plt.xlabel(\"Intervention number\")\n",
    "plt.ylabel(\"no. of accepted sets\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "plt.plot(LensSelection[0][\"e\"][i], label=\"sp False, e\")\n",
    "plt.plot(LensSelection[0][\"e + r\"][i], label=\"sp False, e + r\")\n",
    "plt.plot(LensSelection[6][\"e\"][i], label=\"sp True, e\")\n",
    "plt.plot(LensSelection[6][\"e + r\"][i], label=\"sp True, e + r\")\n",
    "plt.xlabel(\"Intervention number\")\n",
    "plt.ylabel(\"no. of accepted sets\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set max. number of iterations to plot (eg. plot true positive recovery for the first 50 interventions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of graphs used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_parents = np.zeros(N)\n",
    "n_children = np.zeros(N)\n",
    "n_poc = np.zeros(N)\n",
    "n_upstream = np.zeros(N)\n",
    "size_mb = np.zeros(N)\n",
    "for i, case in enumerate(cases):\n",
    "    parents, children, poc, mb = utils.graph_info(case.target, case.sem.W)\n",
    "    ancestors = utils.ancestors(case.target, case.sem.W)\n",
    "    n_parents[i] = len(parents)\n",
    "    n_children[i] = len(children)\n",
    "    n_poc[i] = len(poc)\n",
    "    n_upstream[i] = len(ancestors)\n",
    "    size_mb[i] = len(mb)\n",
    "\n",
    "def plot_hist(data, title):\n",
    "    bins = np.arange(data.min(), data.max()+2)-0.5\n",
    "    hist = plt.hist(data, bins, rwidth=0.5, align='mid', color=\"#BABABA\")#colorsb[2])\n",
    "    plt.xlabel(title)\n",
    "    \n",
    "plt.figure(figsize=(15,3))\n",
    "#plt.subplot(131), plot_hist(n_vars, \"Number of variables\")\n",
    "plt.subplot(151), plot_hist(n_parents, \"Number of parents\"), plt.ylabel(\"Number of graphs\")\n",
    "plt.subplot(152), plot_hist(n_children, \"Number of children\")\n",
    "plt.subplot(153), plot_hist(n_poc, \"Number of parents of children\")\n",
    "plt.subplot(154), plot_hist(size_mb, \"Size of the Markov blanket\")\n",
    "plt.subplot(155), plot_hist(n_upstream, \"Number of upstream variables\")\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(range(12))\n",
    "\n",
    "print(\"%d graphs in total\" % N)\n",
    "plt.savefig(\"figures/graph_properties_comparison.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colors\n",
    "def to_rgb(H, b=1, a=1):\n",
    "    RGBa = []\n",
    "    for h in H:\n",
    "        h = h.lstrip(\"#\")\n",
    "        RGBa.append(tuple(int(h[i:i+2], 16) / 256 * b for i in (0, 2, 4)) + (a,))\n",
    "    return np.array(RGBa)\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('tab20')\n",
    "base = [\"#ff4365\", \"#ffdd43\", \"#59ff43\", \"#43ffdd\", \"#4365ff\", \"#e943ff\", \"#601e9e\", \"#6a6a6a\"]\n",
    "#base = [base[i] for i in [0,2,8,3,1,4,5,6,7]]\n",
    "plt.scatter(np.arange(len(base)), np.ones(len(base)), c = base)\n",
    "colors = to_rgb(base)\n",
    "colorsa = to_rgb(base, a=0.5)\n",
    "colorsb = to_rgb(base, b=0.7)\n",
    "plt.scatter(np.arange(len(colors)), np.zeros(len(colors)), c = colors)\n",
    "plt.scatter(np.arange(len(colors)), np.ones(len(colors))*0.5, c = colorsa)\n",
    "plt.scatter(np.arange(len(colors)), np.ones(len(colors))*-0.5, c = colorsb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots B: Number of interventions required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = gridspec.GridSpec(3, 1, wspace=0.10, hspace=0.3)\n",
    "plt.figure(figsize=(8.5,7))\n",
    "\n",
    "NoIntsAux = copy.deepcopy(NoInts)\n",
    "for no_ints in NoIntsAux:\n",
    "    no_ints[no_ints > max_iter] = max_iter\n",
    "\n",
    "##############################\n",
    "# n=10\n",
    "plt.subplot(gs[0])\n",
    "means = np.mean(NoIntsAux[0][:,:,:], axis=1)\n",
    "\n",
    "dev = 0.2\n",
    "xaxis = np.tile(np.arange(P), (N, 1)) - np.outer(np.linspace(-dev, dev, N), np.ones(P))\n",
    "ecolor = \"#cdcdcd\"\n",
    "for i in range(N):\n",
    "    plt.plot(xaxis[i,:], means[:, i].T, color=ecolor, zorder=0, linewidth=0.5)\n",
    "for i in range(N):\n",
    "    plt.scatter(xaxis[i,:], means[:, i].T, marker=\"o\", c=colors[0:P], zorder=1, edgecolors=colorsb)\n",
    "plt.ylabel(\"Avg. no. of interventions\")\n",
    "ax = plt.gca()\n",
    "ax.set_xticks([0,1,2,3,4,5,5.95,7.05])\n",
    "total_averages = means.mean(axis=1)\n",
    "labels = []\n",
    "for i, avg in enumerate(total_averages):\n",
    "    labels.append(names[i] + \"\\n(%0.2f)\" % avg)\n",
    "ax.set_xticklabels(labels, ha=\"center\", rotation=0)\n",
    "ax.text(0.01,0.027,\"10 obs./sample\", transform=ax.transAxes, fontsize=10, ha=\"left\")\n",
    "\n",
    "##############################\n",
    "# n=100\n",
    "plt.subplot(gs[1])\n",
    "means = np.mean(NoIntsAux[1][:,:,:], axis=1)\n",
    "\n",
    "dev = 0.2\n",
    "xaxis = np.tile(np.arange(P), (N, 1)) - np.outer(np.linspace(-dev, dev, N), np.ones(P))\n",
    "ecolor = \"#cdcdcd\"\n",
    "for i in range(N):\n",
    "    plt.plot(xaxis[i,:], means[:, i].T, color=ecolor, zorder=0, linewidth=0.5)\n",
    "for i in range(N):\n",
    "    plt.scatter(xaxis[i,:], means[:, i].T, marker=\"o\", c=colors[0:P], zorder=1, edgecolors=colorsb)\n",
    "plt.ylabel(\"Avg. no. of interventions\")\n",
    "ax = plt.gca()\n",
    "ax.set_xticks([0,1,2,3,4,5,5.95,7.05])\n",
    "total_averages = means.mean(axis=1)\n",
    "labels = []\n",
    "for i, avg in enumerate(total_averages):\n",
    "    labels.append(names[i] + \"\\n(%0.2f)\" % avg)\n",
    "ax.set_xticklabels(labels, ha=\"center\", rotation=0)\n",
    "ax.text(0.01,0.027,\"100 obs./sample\", transform=ax.transAxes, fontsize=10, ha=\"left\")\n",
    "\n",
    "##############################\n",
    "# n=1000\n",
    "plt.subplot(gs[2])\n",
    "means = np.mean(NoIntsAux[2][:,:,:], axis=1)\n",
    "\n",
    "dev = 0.2\n",
    "xaxis = np.tile(np.arange(P), (N, 1)) - np.outer(np.linspace(-dev, dev, N), np.ones(P))\n",
    "ecolor = \"#cdcdcd\"\n",
    "for i in range(N):\n",
    "    plt.plot(xaxis[i,:], means[:, i].T, color=ecolor, zorder=0, linewidth=0.5)\n",
    "for i in range(N):\n",
    "    plt.scatter(xaxis[i,:], means[:, i].T, marker=\"o\", c=colors[0:P], zorder=1, edgecolors=colorsb)\n",
    "plt.ylabel(\"Avg. no. of interventions\")\n",
    "ax = plt.gca()\n",
    "ax.set_xticks([0,1,2,3,4,5,5.95,7.05])\n",
    "total_averages = means.mean(axis=1)\n",
    "labels = []\n",
    "for i, avg in enumerate(total_averages):\n",
    "    labels.append(names[i] + \"\\n(%0.2f)\" % avg)\n",
    "ax.set_xticklabels(labels, ha=\"center\", rotation=0)\n",
    "ax.text(0.01,0.027,\"1000 obs./sample\", transform=ax.transAxes, fontsize=10, ha=\"left\")\n",
    "\n",
    "#plt.savefig('figures/intervention_numbers_finite.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot D: Sensitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "gs = gridspec.GridSpec(3, 3, wspace=0.10, hspace=0.15)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plot_iter = 50\n",
    "x_axis = np.arange(0, plot_iter)\n",
    "ylim = [-0.05, 1.1]\n",
    "linestyle = ['-', '--', '--', '--', ':', ':', ':', ':']\n",
    "zorder = [1,4,2,3,-1,-2,-3,-4]\n",
    "\n",
    "plots = zip([Trajectories[i] for i in [0,3,6,1,4,7,2,5,8]],\n",
    "            [0.01, 0.0002, 0.0002] * 3,\n",
    "            [10] * 3 + [100] * 3 + [1000] * 3,\n",
    "            [False, False, True] * 3)\n",
    "\n",
    "##############################\n",
    "# Plot trajectories for n=10\n",
    "for i, (all_trajectories, level, sample_size, speedup) in enumerate(plots):\n",
    "    plt.subplot(gs[i])\n",
    "    ax = plt.gca()\n",
    "    print(\"Plotting %d/%d\" % (i+1, len(Trajectories)), end=\"\\r\")\n",
    "    hm_dist = np.zeros((P, N*runs, max_iter+1))\n",
    "    for j, policy_trajectories in enumerate(all_trajectories.values()):\n",
    "        for k, trajectory in enumerate(policy_trajectories):\n",
    "            n = min(plot_iter, len(trajectory))\n",
    "            hm_dist[j, k, 0:n] = trajectory[0:n]\n",
    "    mean = np.mean(hm_dist == 0, axis=1)\n",
    "    # Plot TPR for each policy\n",
    "    for j,name in enumerate(names):\n",
    "        ax.plot(x_axis, mean[j,x_axis], label=name, linewidth=1.5, linestyle = linestyle[j], color=colors[j], zorder=zorder[j])\n",
    "    ax.text(0.05,0.9,\"exp. = %d\" % [0,3,6,1,4,7,2,5,8][i], transform=ax.transAxes)\n",
    "    # Labels / legend\n",
    "    if i < 3:\n",
    "        ax.text(0.5,1.05,\"ICP level=%s speedup=%s\" % (level, speedup), transform=ax.transAxes, fontsize=11, ha=\"center\")\n",
    "    if i % 3 == 2:\n",
    "        ax.text(1.05,0.5,\"%d obs./sample\" % sample_size, transform=ax.transAxes, fontsize=11, va=\"center\", rotation=90)\n",
    "    ax.set_yticklabels([]) if i % 3 != 0 else None\n",
    "    plt.ylim(ylim)\n",
    "    plt.ylabel(\"True positive recovery\") if i % 3 == 0 else None\n",
    "    plt.xlabel(\"Intervention number\") if i >= 6 else None\n",
    "ax.legend(prop=fontP, ncol=5, bbox_to_anchor=(1, -.25))\n",
    "plt.savefig('figures/comparison_tpr.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting parameters\n",
    "\n",
    "gs = gridspec.GridSpec(3, 3, wspace=0.10, hspace=0.3)\n",
    "plt.figure(figsize=(20,10))\n",
    "dev = 0.35\n",
    "xaxis = np.tile(np.arange(P), (N, 1)) - np.outer(np.linspace(-dev, dev, N), np.ones(P))\n",
    "ecolor = \"#cdcdcd\"\n",
    "markers = [\".\", \"$2$\", \"^\", \"s\", \"p\", \"H\"]\n",
    "\n",
    "#-----------------------------------\n",
    "# Function for individual (n=x) plot\n",
    "\n",
    "def point_plot(NoInts, ax, parents = None):\n",
    "    # Plotting\n",
    "    means = NoInts.mean(axis=1)\n",
    "    no_parents = np.array(list(map(lambda case: len(case.truth), cases)))\n",
    "    parents = range(no_parents.min(), no_parents.max() + 1) if parents is None else parents\n",
    "    for p in parents:\n",
    "        idx = idx = np.where(no_parents == p)[0]\n",
    "        # Plot lines first\n",
    "        for i in idx:            \n",
    "            plt.plot(xaxis[i,:], means[:, i].T, color=ecolor, zorder=0, linewidth=0.5)\n",
    "        # Plot dots\n",
    "        for i in idx:\n",
    "            plt.scatter(xaxis[i,:], means[:, i].T, marker=markers[p-1], c=colors[0:P], zorder=1, edgecolors=colorsb)\n",
    "    \n",
    "    # Set labels \n",
    "    #plt.ylabel(\"Avg. no. of interventions\")\n",
    "    ax.set_xticks([0,1,1.95,2.9,3.85,4.85,5.9,7.05])\n",
    "    total_averages = means.mean(axis=1)\n",
    "    labels = []\n",
    "    for i, avg in enumerate(total_averages):\n",
    "        labels.append(names[i] + \"\\n(%0.2f)\" % avg)\n",
    "    ax.set_xticklabels(labels, ha=\"center\", rotation=0)\n",
    "    \n",
    "\n",
    "#---------------------------\n",
    "# Compose all plots together\n",
    "\n",
    "NoIntsAux = copy.deepcopy(NoInts)\n",
    "for no_ints in NoIntsAux:\n",
    "    no_ints[no_ints > max_iter] = max_iter\n",
    "\n",
    "parents = None\n",
    "\n",
    "# n=10, sp=False, level=0.01\n",
    "plt.subplot(gs[0])\n",
    "ax = plt.gca()\n",
    "point_plot(NoIntsAux[0], ax, parents)\n",
    "ax.set_yticks([0, 10, 20, 30, 40, 50])\n",
    "plt.ylim(-5, 55)\n",
    "ax.text(0.01,0.027,\"10 obs./sample, sp=False, ICP level=0.01\", transform=ax.transAxes, fontsize=10, ha=\"left\")\n",
    "\n",
    "# n=100, sp=False, level=0.01\n",
    "plt.subplot(gs[3])\n",
    "ax = plt.gca()\n",
    "point_plot(NoIntsAux[1], ax, parents)\n",
    "ax.set_yticks([0, 10, 20, 30, 40, 50])\n",
    "plt.ylim(-5, 55)\n",
    "ax.text(0.01,0.027,\"100 obs./sample, sp=False, ICP level=0.01\", transform=ax.transAxes, fontsize=10, ha=\"left\")\n",
    "\n",
    "# n=1000, sp=False, level=0.01\n",
    "plt.subplot(gs[6])\n",
    "ax = plt.gca()\n",
    "point_plot(NoIntsAux[2], ax, parents)\n",
    "ax.set_yticks([0, 10, 20, 30, 40, 50])\n",
    "plt.ylim(-5, 55)\n",
    "ax.text(0.01,0.027,\"1000 obs./sample, sp=False, ICP level=0.01\", transform=ax.transAxes, fontsize=10, ha=\"left\")\n",
    "\n",
    "##\n",
    "\n",
    "# n=10, sp=False, level=0.0002\n",
    "plt.subplot(gs[1])\n",
    "ax = plt.gca()\n",
    "point_plot(NoIntsAux[3], ax, parents)\n",
    "ax.set_yticks([0, 10, 20, 30, 40, 50])\n",
    "plt.ylim(-5, 55)\n",
    "ax.text(0.01,0.027,\"10 obs./sample, sp=False, ICP level=0.0002\", transform=ax.transAxes, fontsize=10, ha=\"left\")\n",
    "\n",
    "# n=100, sp=False, level=0.0002\n",
    "plt.subplot(gs[4])\n",
    "ax = plt.gca()\n",
    "point_plot(NoIntsAux[4], ax, parents)\n",
    "ax.set_yticks([0, 10, 20, 30, 40, 50])\n",
    "plt.ylim(-5, 55)\n",
    "ax.text(0.01,0.027,\"100 obs./sample, sp=False, ICP level=0.0002\", transform=ax.transAxes, fontsize=10, ha=\"left\")\n",
    "\n",
    "# n=1000, sp=False, level=0.0002\n",
    "plt.subplot(gs[7])\n",
    "ax = plt.gca()\n",
    "point_plot(NoIntsAux[5], ax, parents)\n",
    "ax.set_yticks([0, 10, 20, 30, 40, 50])\n",
    "plt.ylim(-5, 55)\n",
    "ax.text(0.01,0.027,\"1000 obs./sample, sp=False, ICP level=0.0002\", transform=ax.transAxes, fontsize=10, ha=\"left\")\n",
    "\n",
    "##\n",
    "\n",
    "# n=10, sp=True, level=0.0002\n",
    "plt.subplot(gs[2])\n",
    "ax = plt.gca()\n",
    "point_plot(NoIntsAux[6], ax, parents)\n",
    "ax.set_yticks([0, 10, 20, 30, 40, 50])\n",
    "plt.ylim(-5, 55)\n",
    "ax.text(0.01,0.027,\"10 obs./sample, sp=True, ICP level=0.0002\", transform=ax.transAxes, fontsize=10, ha=\"left\")\n",
    "\n",
    "# n=100, sp=True, level=0.0002\n",
    "plt.subplot(gs[5])\n",
    "ax = plt.gca()\n",
    "point_plot(NoIntsAux[7], ax, parents)\n",
    "ax.set_yticks([0, 10, 20, 30, 40, 50])\n",
    "plt.ylim(-5, 55)\n",
    "ax.text(0.01,0.027,\"100 obs./sample, sp=True, ICP level=0.0002\", transform=ax.transAxes, fontsize=10, ha=\"left\")\n",
    "\n",
    "# n=1000, sp=True, level=0.0002\n",
    "plt.subplot(gs[8])\n",
    "ax = plt.gca()\n",
    "point_plot(NoIntsAux[8], ax, parents)\n",
    "ax.set_yticks([0, 10, 20, 30, 40, 50])\n",
    "plt.ylim(-5, 55)\n",
    "ax.text(0.01,0.027,\"1000 obs./sample, sp=True, ICP level=0.0002\", transform=ax.transAxes, fontsize=10, ha=\"left\")\n",
    "\n",
    "\n",
    "# Build legend\n",
    "legend_elements = []\n",
    "for i,m in enumerate(markers):\n",
    "    legend_elements.append(Line2D([0],[0],\n",
    "                                  marker=m,\n",
    "                                  color=[0,0,0,0],\n",
    "                                  label= '%d parent' % (i+1) + ('s' if i > 0 else ''),\n",
    "                                  markerfacecolor=colorsa[7],\n",
    "                                  markeredgecolor=colors[7],\n",
    "                                  markersize=7))\n",
    "ax.legend(handles=legend_elements,prop=fontP, ncol=6, bbox_to_anchor=(1.03, -0.25))\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('figures/comparison_int_numbers.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = 2\n",
    "thresh = 25\n",
    "experiment = 5\n",
    "idx_bad_performance = np.where(NoInts[experiment].mean(axis=1)[policy,:] > thresh)[0]\n",
    "idx_good_performance = np.where(NoInts[experiment].mean(axis=1)[policy,:] < thresh)[0]\n",
    "\n",
    "cases, results = load_results(experiments[experiment])\n",
    "\n",
    "def policy_results(idx):\n",
    "    \"\"\"Return the results of the selected graphs (idx) for the given policy, accross all runs\"\"\"\n",
    "    policy_results = [] # Stored by runs, ie. 0-axis is the graph, 1-axis is the runs\n",
    "    for i in idx:\n",
    "        policy_results.append([results[policy][r][i] for r in range(runs)])\n",
    "    return np.array(policy_results)\n",
    "\n",
    "def parent_ratio_below_half(idx):\n",
    "    selection = policy_results(idx)\n",
    "    avg_percent_below_half = np.zeros_like(selection)\n",
    "    for i,graph_results in enumerate(selection):\n",
    "        for j, run_result in enumerate(graph_results):\n",
    "            parents = cases[idx[i]].truth\n",
    "            ratios_parents = run_result.ratios()[:, list(parents)]\n",
    "            avg_percent_below_half[i,j] = np.mean(ratios_parents < 0.5)\n",
    "    return avg_percent_below_half\n",
    "    \n",
    "def markov_blanket_composition(idx):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(parent_ratio_below_half(idx_good_performance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(parent_ratio_below_half(idx_bad_performance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
